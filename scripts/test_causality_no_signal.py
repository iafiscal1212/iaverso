#!/usr/bin/env python3
"""
Test de Causalidad con Ruido Blanco
===================================

Verifica que el motor de causalidad NO encuentra se√±ales espurias
cuando se le alimenta con ruido blanco.

NORMA DURA: Un sistema robusto debe dar negativo ante la ausencia de se√±al.

Metodolog√≠a:
1. Generar series de ruido blanco (Gaussiano)
2. Ejecutar el motor de causalidad
3. Verificar que las "correlaciones" encontradas son < umbral estad√≠stico
4. Verificar que no se generan hip√≥tesis falsas

Esto es un "null test" - esperamos que NO encuentre nada.
"""

import sys
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import datetime
from scipy import stats

sys.path.insert(0, '/root/NEO_EVA')

from core.norma_dura_config import CONSTANTS


# =============================================================================
# CONFIGURACI√ìN DE TEST
# =============================================================================

# Tama√±o de series para el test
# ORIGEN: 100 es suficiente para CLT, pero 500 da m√°s poder estad√≠stico
N_SAMPLES = 500

# N√∫mero de series a generar
N_SERIES = 10

# Alpha para tests estad√≠sticos
# ORIGEN: 0.05 es el est√°ndar en estad√≠stica
ALPHA = 0.05

# Tolerancia para falsos positivos
# ORIGEN: Esperamos ~5% de falsos positivos por azar (equal a alpha)
FALSE_POSITIVE_TOLERANCE = ALPHA * 2  # Dar margen de 2x


# =============================================================================
# GENERADORES DE RUIDO
# =============================================================================

def generate_white_noise(
    n_samples: int,
    n_series: int,
    seed: Optional[int] = None
) -> np.ndarray:
    """
    Generar matriz de ruido blanco Gaussiano.

    Args:
        n_samples: Longitud de cada serie
        n_series: N√∫mero de series
        seed: Semilla para reproducibilidad

    Returns:
        Matriz (n_samples, n_series) de ruido blanco
    """
    if seed is not None:
        np.random.seed(seed)

    # Ruido blanco Gaussiano est√°ndar
    # ORIGEN: N(0,1) es la definici√≥n de ruido blanco Gaussiano
    return np.random.randn(n_samples, n_series)


def verify_whiteness(series: np.ndarray) -> Dict:
    """
    Verificar que una serie es efectivamente ruido blanco.

    Tests:
    1. Media ‚âà 0
    2. Varianza ‚âà 1
    3. Autocorrelaci√≥n ‚âà 0 para lag > 0
    4. Normalidad (Shapiro-Wilk)
    """
    n = len(series)

    # Test de media (t-test contra 0)
    t_stat, p_mean = stats.ttest_1samp(series, 0)

    # Test de varianza (chi-squared)
    var = np.var(series, ddof=1)
    chi2_stat = (n - 1) * var / 1.0  # H0: sigma^2 = 1
    p_var = 2 * min(
        stats.chi2.cdf(chi2_stat, n - 1),
        1 - stats.chi2.cdf(chi2_stat, n - 1)
    )

    # Autocorrelaci√≥n
    # ORIGEN: Umbral de significancia = 2/sqrt(n)
    acf_threshold = 2 / np.sqrt(n)
    lags_to_test = min(20, n // 4)
    acf_values = []
    for lag in range(1, lags_to_test + 1):
        acf = np.corrcoef(series[:-lag], series[lag:])[0, 1]
        acf_values.append(acf)

    significant_acf = sum(1 for a in acf_values if abs(a) > acf_threshold)

    # Normalidad (Shapiro-Wilk, limitado a 5000 muestras)
    if n > 5000:
        sample_for_test = np.random.choice(series, 5000, replace=False)
    else:
        sample_for_test = series
    _, p_normal = stats.shapiro(sample_for_test)

    return {
        'mean': float(np.mean(series)),
        'std': float(np.std(series, ddof=1)),
        'p_mean_zero': float(p_mean),
        'p_var_one': float(p_var),
        'n_significant_acf': significant_acf,
        'acf_threshold': float(acf_threshold),
        'p_normal': float(p_normal),
        'is_white_noise': (
            p_mean > ALPHA and
            p_var > ALPHA and
            significant_acf <= 1 and  # Permitir 1 por azar
            p_normal > ALPHA
        )
    }


# =============================================================================
# SIMULADOR DE MOTOR DE CAUSALIDAD
# =============================================================================

class CausalityEngine:
    """
    Motor de causalidad end√≥geno.

    Busca correlaciones y patrones causales entre series.
    NORMA DURA: Todos los umbrales son estad√≠sticos.
    """

    def __init__(self, data: np.ndarray):
        """
        Args:
            data: Matriz (n_samples, n_series)
        """
        self.data = data
        self.n_samples, self.n_series = data.shape

        # Umbral de correlaci√≥n significativa
        # ORIGEN: 2/sqrt(n) es el umbral est√°ndar
        self.corr_threshold = 2 / np.sqrt(self.n_samples)

    def compute_correlations(self) -> np.ndarray:
        """Calcular matriz de correlaci√≥n."""
        return np.corrcoef(self.data.T)

    def find_significant_correlations(self) -> List[Tuple[int, int, float]]:
        """
        Encontrar pares con correlaci√≥n significativa.

        Returns:
            Lista de (serie_i, serie_j, correlaci√≥n)
        """
        corr_matrix = self.compute_correlations()
        significant = []

        for i in range(self.n_series):
            for j in range(i + 1, self.n_series):
                corr = corr_matrix[i, j]
                if abs(corr) > self.corr_threshold:
                    significant.append((i, j, float(corr)))

        return significant

    def test_granger_causality(
        self,
        series_x: np.ndarray,
        series_y: np.ndarray,
        max_lag: int = 5
    ) -> Dict:
        """
        Test simplificado de causalidad de Granger.

        H0: X no Granger-causa Y
        """
        from scipy.stats import f as f_dist

        n = len(series_y) - max_lag

        # Modelo restringido: Y ~ Y_lags
        y_lags = np.column_stack([
            series_y[max_lag - i - 1:-i - 1] for i in range(max_lag)
        ])
        y_target = series_y[max_lag:]

        # Modelo completo: Y ~ Y_lags + X_lags
        x_lags = np.column_stack([
            series_x[max_lag - i - 1:-i - 1] for i in range(max_lag)
        ])
        full_features = np.hstack([y_lags, x_lags])

        # Ajuste por m√≠nimos cuadrados
        # Modelo restringido
        beta_r = np.linalg.lstsq(y_lags, y_target, rcond=None)[0]
        residuals_r = y_target - y_lags @ beta_r
        rss_r = np.sum(residuals_r ** 2)

        # Modelo completo
        beta_f = np.linalg.lstsq(full_features, y_target, rcond=None)[0]
        residuals_f = y_target - full_features @ beta_f
        rss_f = np.sum(residuals_f ** 2)

        # F-statistic
        df_r = max_lag  # Par√°metros adicionales en modelo completo
        df_f = n - 2 * max_lag  # Grados de libertad residuales

        if df_f <= 0 or rss_f <= 0:
            return {'f_stat': 0, 'p_value': 1.0, 'significant': False}

        f_stat = ((rss_r - rss_f) / df_r) / (rss_f / df_f)
        p_value = 1 - f_dist.cdf(f_stat, df_r, df_f)

        return {
            'f_stat': float(f_stat),
            'p_value': float(p_value),
            'significant': p_value < ALPHA
        }

    def full_analysis(self) -> Dict:
        """
        An√°lisis completo de causalidad.

        Returns:
            Diccionario con resultados
        """
        results = {
            'n_samples': self.n_samples,
            'n_series': self.n_series,
            'corr_threshold': self.corr_threshold,
            'significant_correlations': [],
            'granger_tests': [],
            'n_false_positives_corr': 0,
            'n_false_positives_granger': 0,
        }

        # Correlaciones
        sig_corrs = self.find_significant_correlations()
        results['significant_correlations'] = sig_corrs
        results['n_false_positives_corr'] = len(sig_corrs)

        # Granger (solo para los pares correlacionados, si hay)
        for i, j, corr in sig_corrs[:5]:  # Limitar a 5 para eficiencia
            granger = self.test_granger_causality(
                self.data[:, i], self.data[:, j]
            )
            if granger['significant']:
                results['n_false_positives_granger'] += 1
            results['granger_tests'].append({
                'pair': (i, j),
                'correlation': corr,
                **granger
            })

        return results


# =============================================================================
# TESTS PRINCIPALES
# =============================================================================

def run_null_test(seed: int = 42) -> Dict:
    """
    Ejecutar test nulo completo.

    Con ruido blanco, NO deber√≠amos encontrar se√±ales.
    """
    results = {
        'timestamp': datetime.now().isoformat(),
        'seed': seed,
        'n_samples': N_SAMPLES,
        'n_series': N_SERIES,
        'alpha': ALPHA,
        'tests': []
    }

    print("\n" + "=" * 70)
    print("üî¨ TEST DE CAUSALIDAD CON RUIDO BLANCO")
    print("=" * 70)
    print(f"\nüìä Generando {N_SERIES} series de ruido blanco ({N_SAMPLES} muestras)")

    # Generar ruido
    noise = generate_white_noise(N_SAMPLES, N_SERIES, seed=seed)

    # Verificar que es ruido blanco
    print("\nüìã Verificando whiteness de las series...")
    whiteness_results = []
    for i in range(N_SERIES):
        wh = verify_whiteness(noise[:, i])
        whiteness_results.append(wh)
        status = "‚úÖ" if wh['is_white_noise'] else "‚ùå"
        if not wh['is_white_noise']:
            print(f"  Serie {i}: {status} (puede afectar el test)")

    all_white = all(w['is_white_noise'] for w in whiteness_results)
    results['all_series_white'] = all_white

    if not all_white:
        print("  ‚ö†Ô∏è  Algunas series no pasan el test de whiteness")
    else:
        print("  ‚úÖ Todas las series son ruido blanco verificado")

    # Ejecutar motor de causalidad
    print("\nüîç Ejecutando motor de causalidad...")
    engine = CausalityEngine(noise)
    analysis = engine.full_analysis()
    results['analysis'] = analysis

    print(f"\nüìä Resultados:")
    print(f"  Umbral de correlaci√≥n: {analysis['corr_threshold']:.4f}")
    print(f"  Correlaciones 'significativas': {analysis['n_false_positives_corr']}")
    print(f"  Tests Granger 'positivos': {analysis['n_false_positives_granger']}")

    # Evaluar
    # ORIGEN: Esperamos ~5% de falsos positivos por azar
    n_pairs = N_SERIES * (N_SERIES - 1) // 2
    expected_false_positives = n_pairs * ALPHA
    tolerance = expected_false_positives * 2  # 2x margen

    print(f"\nüìà Evaluaci√≥n:")
    print(f"  Pares totales: {n_pairs}")
    print(f"  Falsos positivos esperados (Œ±={ALPHA}): {expected_false_positives:.1f}")
    print(f"  Tolerancia (2x): {tolerance:.1f}")
    print(f"  Falsos positivos observados: {analysis['n_false_positives_corr']}")

    # Determinar si pasa
    passes_corr = analysis['n_false_positives_corr'] <= tolerance
    passes_granger = analysis['n_false_positives_granger'] <= max(1, tolerance // 2)

    results['passes_correlation_test'] = passes_corr
    results['passes_granger_test'] = passes_granger
    results['overall_pass'] = passes_corr and passes_granger

    print("\n" + "-" * 50)
    if passes_corr:
        print("  ‚úÖ Test de correlaciones: PASA")
    else:
        print("  ‚ùå Test de correlaciones: FALLA")
        print("     Demasiados falsos positivos detectados")

    if passes_granger:
        print("  ‚úÖ Test de Granger: PASA")
    else:
        print("  ‚ùå Test de Granger: FALLA")
        print("     Causalidades espurias detectadas")

    # Mostrar correlaciones falsas (si hay)
    if analysis['significant_correlations']:
        print("\n‚ö†Ô∏è  Correlaciones espurias encontradas:")
        for i, j, corr in analysis['significant_correlations'][:5]:
            print(f"     Series {i}-{j}: r={corr:.4f}")

    return results


def run_multiple_tests(n_tests: int = 5) -> Dict:
    """
    Ejecutar m√∫ltiples tests con diferentes seeds.
    """
    print("\n" + "=" * 70)
    print("üî¨ BATTERY DE TESTS NULOS")
    print("=" * 70)

    all_results = []
    passes = 0

    for i in range(n_tests):
        seed = 42 + i * 17  # Seeds diferentes
        print(f"\n--- Test {i+1}/{n_tests} (seed={seed}) ---")
        result = run_null_test(seed=seed)
        all_results.append(result)
        if result['overall_pass']:
            passes += 1

    # Resumen
    print("\n" + "=" * 70)
    print("üìã RESUMEN DE BATTERY")
    print("=" * 70)
    print(f"  Tests ejecutados: {n_tests}")
    print(f"  Tests pasados: {passes}")
    print(f"  Tasa de √©xito: {passes/n_tests:.1%}")

    # Evaluar
    # ORIGEN: Esperamos que al menos 80% pasen (margen para variabilidad)
    min_pass_rate = 0.8
    overall_pass = (passes / n_tests) >= min_pass_rate

    if overall_pass:
        print(f"\n‚úÖ BATTERY PASA: {passes}/{n_tests} tests exitosos")
    else:
        print(f"\n‚ùå BATTERY FALLA: Solo {passes}/{n_tests} tests pasaron")
        print("   El motor de causalidad puede estar generando falsos positivos")

    return {
        'n_tests': n_tests,
        'n_passed': passes,
        'pass_rate': passes / n_tests,
        'overall_pass': overall_pass,
        'individual_results': all_results
    }


def main():
    """Funci√≥n principal."""
    import argparse
    import json

    parser = argparse.ArgumentParser(description='Test de Causalidad con Ruido Blanco')
    parser.add_argument('--n-tests', type=int, default=3, help='N√∫mero de tests')
    parser.add_argument('--output', type=str, help='Guardar resultados en JSON')
    parser.add_argument('--verbose', '-v', action='store_true', help='Mostrar detalles')

    args = parser.parse_args()

    if args.n_tests > 1:
        results = run_multiple_tests(n_tests=args.n_tests)
    else:
        results = run_null_test()

    if args.output:
        with open(args.output, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        print(f"\nüìÑ Resultados guardados en: {args.output}")

    # Exit code
    overall = results.get('overall_pass', results.get('passes_correlation_test', False))
    sys.exit(0 if overall else 1)


if __name__ == '__main__':
    main()


# =============================================================================
# BLOQUE DE AUDITOR√çA NORMA DURA
# =============================================================================
"""
MAGIC NUMBERS AUDIT
==================

CONSTANTES EN ESTE ARCHIVO:

PAR√ÅMETROS DE TEST:
- N_SAMPLES = 500: ORIGEN: 5x CLT m√≠nimo para poder estad√≠stico
- N_SERIES = 10: ORIGEN: Suficiente para n_pairs = 45 (estad√≠sticamente significativo)
- ALPHA = 0.05: ORIGEN: Nivel de significancia estad√≠stico est√°ndar
- FALSE_POSITIVE_TOLERANCE = 2*ALPHA: ORIGEN: Margen 2x para variabilidad

UMBRALES ESTAD√çSTICOS:
- corr_threshold = 2/sqrt(n): ORIGEN: Umbral de significancia para correlaci√≥n
- Granger max_lag = 5: ORIGEN: T√≠pico para series econ√≥micas/temporales

EVALUACI√ìN:
- min_pass_rate = 0.8: ORIGEN: 80% es est√°ndar para robustez de battery tests

TODAS LAS DECISIONES TIENEN ORIGEN DOCUMENTADO.
"""
