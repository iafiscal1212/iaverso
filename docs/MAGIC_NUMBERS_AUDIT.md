# Auditor√≠a de N√∫meros M√°gicos - NEO_EVA

## Norma Dura:
**"Ning√∫n n√∫mero entra al c√≥digo sin poder explicar de qu√© distribuci√≥n de los datos sale"**

---

## üî¥ VIOLACIONES ACTUALES (deben corregirse)

### 1. Scoring con n√∫mero m√°gico 20
```python
# Archivo: agents_truly_endogenous.py:279
score = max(0, 100 - z_score * 20)
```
**PROBLEMA**: El `20` es arbitrario. ¬øPor qu√© 20 y no 15 o 25?

**CORRECCI√ìN REQUERIDA**: El factor debe derivarse de los datos. Por ejemplo:
- Usar IQR de la distribuci√≥n aprendida
- Usar std de la distribuci√≥n observada
- El agente debe calcular su propio "peso" de penalizaci√≥n

### 2. Default std como 20% de media
```python
# Archivo: agents_truly_endogenous.py:273
std_learned = np.std(learned_temps) if len(learned_temps) > 1 else mean_learned * 0.2
```
**PROBLEMA**: El `0.2` (20%) es arbitrario.

**CORRECCI√ìN REQUERIDA**: Si no hay suficientes datos para std, el agente no deber√≠a poder evaluar (return None).

### 3. Score por defecto de 50
```python
# Archivo: agents_truly_endogenous.py:281
score = 50
```
**PROBLEMA**: ¬øPor qu√© 50? Es un n√∫mero arbitrario.

**CORRECCI√ìN REQUERIDA**: Si no puede calcular score, deber√≠a retornar `None` o "indeterminado".

### 4. Filtro de temperaturas 50-1000
```python
# Archivo: agents_truly_endogenous.py:268
learned_temps = [f['value'] for f in temp_facts if 50 < f['value'] < 1000]
```
**PROBLEMA**: Los l√≠mites 50 y 1000 son arbitrarios.

**CORRECCI√ìN REQUERIDA**: No filtrar. Usar todos los valores extra√≠dos, o que el agente decida qu√© es outlier bas√°ndose en estad√≠sticas (ej: ¬±3œÉ).

### 5. Curiosidad por defecto 0.5
```python
# Archivo: agents_truly_endogenous.py:93
curiosity = self.personality.get('curiosity', 0.5)
```
**PROBLEMA**: El 0.5 es arbitrario.

**JUSTIFICACI√ìN POSIBLE**: Es el punto medio de una escala 0-1. Esto S√ç es justificable matem√°ticamente como "neutro" en una distribuci√≥n uniforme.

**VEREDICTO**: ‚ö†Ô∏è Aceptable pero documentar.

### 6. L√≠mite de contexto 200 caracteres
```python
# Archivo: real_knowledge_source.py:317 (extractor)
context = sentence.strip()[:200]
```
**PROBLEMA**: ¬øPor qu√© 200?

**CORRECCI√ìN**: Este es un l√≠mite t√©cnico de display, no afecta la ciencia. Pero deber√≠a documentarse.

---

## üü° N√öMEROS T√âCNICOS (aceptables con documentaci√≥n)

### L√≠mites de API
- `timeout=30` - L√≠mite t√©cnico de red
- `limit=5`, `limit=10` - L√≠mite de resultados de API
- `size=3` - L√≠mite de papers a buscar

**VEREDICTO**: Estos no afectan la ciencia, solo la cantidad de datos.

### Escala de scores 0-100
- `score = max(0, 100 - ...)`

**VEREDICTO**: Es una escala arbitraria pero est√°ndar. Lo importante es la comparaci√≥n relativa, no el n√∫mero absoluto.

---

## üü¢ N√öMEROS DERIVADOS DE DATOS (correctos)

### Estad√≠sticas de distribuci√≥n
```python
mean_val = np.mean(values)  # ‚úì Viene de datos
std_val = np.std(values)    # ‚úì Viene de datos
min_val = min(values)       # ‚úì Viene de datos
max_val = max(values)       # ‚úì Viene de datos
```

### Percentiles
```python
q1, q3 = vals.quantile([0.25, 0.75])  # ‚úì Definici√≥n matem√°tica est√°ndar
iqr = q3 - q1                          # ‚úì Definici√≥n matem√°tica
```

---

## üìã PLAN DE CORRECCI√ìN

### Prioridad Alta:
1. Eliminar el factor `20` en scoring - usar IQR o std calculada
2. No usar `0.2` como default std - retornar None si insuficientes datos
3. No usar `50` como score default - retornar None

### Prioridad Media:
4. Eliminar filtro `50 < x < 1000` - usar detecci√≥n de outliers estad√≠stica

### Documentar:
5. Curiosidad 0.5 - punto medio de escala uniforme
6. L√≠mites t√©cnicos de API - no afectan ciencia

---

## IMPLEMENTACI√ìN CORRECTA

```python
def evaluate_temperature(self, planet_temp, learned_temps):
    """
    Evaluaci√≥n sin n√∫meros m√°gicos.

    Todos los umbrales vienen de los datos.
    """
    if len(learned_temps) < 5:
        return {
            'can_evaluate': False,
            'reason': 'Insuficientes datos aprendidos'
        }

    # Calcular estad√≠sticas de la distribuci√≥n aprendida
    mean_learned = np.mean(learned_temps)
    std_learned = np.std(learned_temps)
    q1 = np.percentile(learned_temps, 25)
    q3 = np.percentile(learned_temps, 75)
    iqr = q3 - q1

    # Detectar outliers con criterio estad√≠stico (Tukey)
    # NO es un n√∫mero m√°gico, es una definici√≥n matem√°tica
    lower_bound = q1 - 1.5 * iqr  # Tukey fence
    upper_bound = q3 + 1.5 * iqr  # Tukey fence

    # Calcular z-score
    if std_learned > 0:
        z_score = abs(planet_temp - mean_learned) / std_learned
    else:
        return {'can_evaluate': False, 'reason': 'std = 0'}

    # Score basado en distribuci√≥n normal
    # Prob de estar a ‚â§z desviaciones = scipy.stats.norm.cdf(z)
    from scipy.stats import norm
    prob_closer = 2 * (1 - norm.cdf(z_score))  # Two-tailed
    score = 100 * prob_closer  # Ahora viene de la distribuci√≥n

    return {
        'can_evaluate': True,
        'score': score,
        'justification': {
            'mean_learned': mean_learned,
            'std_learned': std_learned,
            'z_score': z_score,
            'probability': prob_closer,
            'n_samples': len(learned_temps),
        }
    }
```

---

## CHECKLIST FINAL

Antes de publicar, verificar que CADA n√∫mero:

- [ ] Viene de `np.mean()`, `np.std()`, `np.percentile()` de datos
- [ ] O es una constante matem√°tica definida (œÄ, e, 1.5 para Tukey)
- [ ] O es un l√≠mite t√©cnico documentado (timeout, API limits)
- [ ] O se retorna None/indeterminado en lugar de asumir

**Si no puedes explicar de qu√© distribuci√≥n sale, est√° prohibido.**
